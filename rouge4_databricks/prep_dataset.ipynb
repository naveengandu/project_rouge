{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e929e710-636a-4741-b84a-4638c25c21dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install tensorflow opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "088421d4-239e-4712-8ccf-6117e1e9c391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "from azure.storage.filedatalake import DataLakeServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c2f689e-f545-4f08-9384-3a8c0562b8f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assign storage account and containers values to var\n",
    "account_name = \"rougestorageacc1\"\n",
    "account_key = dbutils.secrets.get(scope=\"rouge4kv1\", key=\"rougestorageacc1key1\")\n",
    "source_container = \"stagekaggledata\"\n",
    "dest_container = \"processkaggledata\"\n",
    "train_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb2e57cb-e45e-4d88-9c13-3c0d2e1e1fe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate using account key\n",
    "service_client = DataLakeServiceClient(\n",
    "    account_url=f\"https://{account_name}.dfs.core.windows.net\",\n",
    "    credential=account_key\n",
    ")\n",
    "\n",
    "source_fs = service_client.get_file_system_client(file_system=source_container)\n",
    "dest_fs = service_client.get_file_system_client(file_system=dest_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1075f575-684b-46bf-9b5f-bd4ded6704b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the data for training and validation into a new destination container and log the number of images in the resulting classes. \n",
    "\n",
    "# SUMMARY LOG\n",
    "split_summary = {}\n",
    "\n",
    "# Process each class folder\n",
    "class_folders = [p.name for p in source_fs.get_paths(path=\"\", recursive=False) if p.is_directory]\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    print(f\"\\nðŸ” Processing class: {class_folder}\")\n",
    "    \n",
    "    images = [f.name for f in source_fs.get_paths(path=class_folder, recursive=False) if not f.is_directory]\n",
    "    total = len(images)\n",
    "\n",
    "    if total == 0:\n",
    "        print(f\"âš ï¸  Skipping {class_folder}: No images found.\")\n",
    "        continue\n",
    "\n",
    "    random.shuffle(images)\n",
    "    split_idx = int(total * train_ratio)\n",
    "    train_imgs = images[:split_idx]\n",
    "    val_imgs = images[split_idx:]\n",
    "\n",
    "    split_summary[class_folder] = {\n",
    "        \"total\": total,\n",
    "        \"train\": len(train_imgs),\n",
    "        \"validation\": len(val_imgs)\n",
    "    }\n",
    "\n",
    "    # Copy to train\n",
    "    for img_path in train_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        dest_path = f\"train/{class_folder}/{img_name}\"\n",
    "        src_client = source_fs.get_file_client(img_path)\n",
    "        dest_client = dest_fs.get_file_client(dest_path)\n",
    "\n",
    "        dest_client.create_file()\n",
    "        dest_client.append_data(src_client.download_file().readall(), 0)\n",
    "        dest_client.flush_data(src_client.get_file_properties().size)\n",
    "\n",
    "    # Copy to validation\n",
    "    for img_path in val_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        dest_path = f\"validation/{class_folder}/{img_name}\"\n",
    "        src_client = source_fs.get_file_client(img_path)\n",
    "        dest_client = dest_fs.get_file_client(dest_path)\n",
    "\n",
    "        dest_client.create_file()\n",
    "        dest_client.append_data(src_client.download_file().readall(), 0)\n",
    "        dest_client.flush_data(src_client.get_file_properties().size)\n",
    "\n",
    "    print(f\"âœ… Split complete for '{class_folder}': {len(train_imgs)} train, {len(val_imgs)} validation\")\n",
    "\n",
    "# Summary Report\n",
    "print(\"\\nðŸ“Š Split Summary:\")\n",
    "for cls, stats in split_summary.items():\n",
    "    print(f\" - {cls}: Total={stats['total']} | Train={stats['train']} | Validation={stats['validation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee83fc32-b2e6-4ddc-9a55-9c5306072ab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# verify that the dataset is available in the specified storage account/container.\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{account_name}.dfs.core.windows.net\",\n",
    "    f\"{account_key}\"\n",
    ")\n",
    "\n",
    "display(dbutils.fs.ls(f\"abfss://{dest_container}@{account_name}.dfs.core.windows.net/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a46aa74-3cdf-412a-b2fe-c57f25459e5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assign values to var\n",
    "catalog = \"main\"\n",
    "schema = \"ml_data\"\n",
    "volume_name = \"processkaggledata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92cb824f-44df-4067-88f4-40e1e1f52dc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "to_crop = [\"train\", \"validation\"]\n",
    "root_path = f\"/Volumes/{catalog}/{schema}/{volume_name}\"\n",
    "s = 160     # side-length of crop (tunable)\n",
    "stride = 32 # sliding window stride (can also tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "702b71ad-fc5a-4485-9d9d-26f42126e3af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define image processing functions\n",
    "\n",
    "# Get HSV feature map\n",
    "def get_hsv_feature_map(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    s_channel = hsv[:, :, 1].astype(np.float32)  # Saturation channel\n",
    "    return s_channel\n",
    "\n",
    "# Get the best coordinates for cropping an image, img, given its feature map, window size (s x s) and stride.\n",
    "def get_best_crop(img, feature_map, s, stride):\n",
    "    h, w = feature_map.shape\n",
    "    max_score = -1\n",
    "    best_crop_coords = (0, 0)\n",
    "\n",
    "    for y in range(0, h - s + 1, stride):\n",
    "        for x in range(0, w - s + 1, stride):\n",
    "            window = feature_map[y:y + s, x:x + s]\n",
    "            score = np.sum(window)\n",
    "\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_crop_coords = (x, y)\n",
    "\n",
    "    x, y = best_crop_coords\n",
    "    return img[y:y + s, x:x + s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0d56f25-decc-4565-b03d-db5a70e5d2c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Scan and crop images from the dataset\n",
    "\n",
    "for dataset in to_crop:\n",
    "    source_root = f\"{root_path}/{dataset}\"\n",
    "    target_root = f\"{root_path}/{dataset}_cropped\"\n",
    "    for class_name in tqdm(os.listdir(source_root)):\n",
    "        class_path = os.path.join(source_root, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        # Create same class folder in output\n",
    "        target_class_path = os.path.join(target_root, class_name)\n",
    "        os.makedirs(target_class_path, exist_ok=True)\n",
    "\n",
    "        for fname in os.listdir(class_path):\n",
    "            if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "\n",
    "            src_path = os.path.join(class_path, fname)\n",
    "            dst_path = os.path.join(target_class_path, fname)\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(src_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "\n",
    "                feature_map = get_hsv_feature_map(img)\n",
    "\n",
    "                # Skip if image smaller than crop size\n",
    "                if img.shape[0] < s or img.shape[1] < s:\n",
    "                    continue\n",
    "\n",
    "                crop = get_best_crop(img, feature_map, s=s, stride=stride)\n",
    "\n",
    "                # Save cropped image\n",
    "                cv2.imwrite(dst_path, crop)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {src_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b51e73c-d6ac-4114-bcaa-4bb76db013e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following code is used to probe/verify the size of the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b02c5e99-1b35-4247-8c56-79473720f4b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get an overview of the image dimensions in the dataset\n",
    "\n",
    "image_dir = f\"/Volumes/{catalog}/{schema}/{volume_name}/train\"\n",
    "sizes = []\n",
    "\n",
    "for root, _, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            path = os.path.join(root, file)\n",
    "            try:\n",
    "                with Image.open(path) as img:\n",
    "                    sizes.append(img.size)  # (width, height)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {path}: {e}\")\n",
    "\n",
    "# Quick summary\n",
    "widths, heights = zip(*sizes)\n",
    "print(f\"Total images: {len(sizes)}\")\n",
    "print(f\"Min size: {min(widths)}x{min(heights)}\")\n",
    "print(f\"Max size: {max(widths)}x{max(heights)}\")\n",
    "print(f\"Avg size: {sum(widths)//len(widths)}x{sum(heights)//len(heights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b90708-5aa1-4a46-a4b1-92068c9ac88b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract a region of interest for a given input image. Returns the cropped image, the coordinates used to crop the image and the max score (max sum of the array values over the feature map) associated with it. \n",
    "\n",
    "def find_feature_dense_crop(image_path, s=64, stride=32):\n",
    "    \"\"\"\n",
    "    Given an image path, find a sÃ—s crop with highest edge density.\n",
    "    \"\"\"\n",
    "    # Load and convert image to grayscale\n",
    "    img = cv2.imread(image_path)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    s_channel = hsv[:, :, 1]\n",
    "    edge_map = s_channel.astype(np.float32)\n",
    "\n",
    "    h, w = edge_map.shape\n",
    "    max_score = -1\n",
    "    best_crop_coords = (0, 0)\n",
    "\n",
    "    # Slide a window and sum edge intensities\n",
    "    for y in range(0, h - s + 1, stride):\n",
    "        for x in range(0, w - s + 1, stride):\n",
    "            window = edge_map[y:y+s, x:x+s]\n",
    "            score = np.sum(window)\n",
    "\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_crop_coords = (x, y)\n",
    "\n",
    "    # Extract crop from original image\n",
    "    x, y = best_crop_coords\n",
    "    cropped_img = img[y:y+s, x:x+s]\n",
    "    return cropped_img, best_crop_coords, max_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71660924-5393-4943-9dc9-fc176c88d9b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the auto-cropped image to verify the results. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_img = f\"/Volumes/{catalog}/{schema}/{volume_name}/train/brownspot/BROWNSPOT1_013.jpg\"\n",
    "crop, coords, score = find_feature_dense_crop(sample_img)\n",
    "\n",
    "print(f\"Crop top-left: {coords}, Feature density score: {score}\")\n",
    "plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Auto-cropped high-density region\")\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 289984376699921,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "prep_dataset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
